# 结构化机器学习项目(Structuring Machine Learning Projects)
## 1 机器学习（ML）策略1
### 1.1 ML策略
当我们最初得到一个深度神经网络模型时，我们可能希望从很多方面来对它进行优化，例如：
* Collect more data
* Collect more diverse training set
* Train algorithm longer with gradient descent
* Try Adam instead of gradient descent
* Try bigger network
* Try smaller network
* Try dropout
* Add L2 regularization
Network architecture: Activation functions, #hidden units...
可选择的方法很多，也很复杂、繁琐。盲目选择、尝试不仅耗费时间而且可能效果甚
微。因此，使用快速、有效的策略来优化机器学习模型是非常必要的。
### 1.2 正交化(Orthogonalization)
* 正交化方法，即在调试机器学习中的超参数数，每次只调试一个参数而保持其他参数不变，保证模型只改变对应于一个参数的某一性能的调参策略。
* 对应到机器学习监督式学习模型中，可以大致分成四个独立的“功能”：
Fit training set well on cost function
Fit dev set well on cost function
Fit test set well on cost function
Performs well in real world
其中，第一条优化训练集可以通过使用更复杂神经网络、使用Adam等优化算法来实现；第二条优化验证集可以通过正则化、采用更多训练样本来实现；第三条优化测试集可以通过使用更多的验证集样本来实现；第四条提升实际应用模型可以通过更换验证集、使用新的cost function来实现。每一种“功能”对应不同的调节方法，相应的调节功能只会改变对应的“功能”。
* early stopping在模型功能调试中并不推荐使用。因为early stopping在提升验证集性能的同时降低了训练集的性能，不具有正交性。

### 1.3~1.4 单值评估指标/优化指标和满意指标
* 构建、优化机器学习模型时，单值评价指标非常必要。有了量化的单值评价指标后，我们就能根据这一指标比较不同超参数(两个及以上)对应的模型的优劣，从而选择最优的那个模型并继续进行迭代优化。
* 把所有的性能指标都综合在一起，构成单值评价指标是比较困难的。我们可以把某些性能作为优化指标（Optimizing metic），寻求最优化值；而某些性能作为满意指标（Satisficing metic），只要满足设定的阈值即可，即不考虑这些指标的优化问题。
### 1.5~1.8 Train/dev/test distributions/ 开发集和测试集大小 改变dev/test sets和指标
* 验证集用来验证针对于不同算法通过训练集训练出来的模型，选出表现最好的那个算法模型；测试集用来检测最终选出的该模型的实际表现性能。原则上应该尽量保证dev sets和test sets来源于同一分布且都反映了实际样本的情况。
* 目前深度学习中样本数量很大，通常将相应的比例设为98%/1%/1%或者99%/1%。
* 实际应用中，可能只有train/dev sets，而没有test sets，这种情况也是允许的，只要算法模型没有对dev sets过拟合。但是，条件允许的话，最好是有test sets，以实现无偏估计。
* 算法模型的评价标准有时候需要根据实际情况进行动态调整，目的是让算法模型在实
际应用中有更好的效果。一个是根据实际改变评估模型的cost function，另一个是dev/test sets与实际使用的样本分布不一致，也需要动态改变评价标准。

### 1.9~1.11 可避免偏差/human-level error/surpassing human-level performance 
* 把training error与human-level error之间的差值称为avoidable bias；把dev error与training error之间的差值称为avoidable variance。根据bias和variance值的相对大小，可以知道算法模型是否发生了欠拟合或者过拟合。在训练模型中不必使bias和variance值达到绝对最小，该值是与human-level error相对的。
* human-level performance能够代表bayes optimal error，但不同人群的human-level error不同，一般来说，我们将表现最好的数据即human-level error最低的作为human-level performance。选择不同的human-levelerror，有时候会影响bias和variance值的相对变化。当然这种情况一般只会在模型表现很好，接近bayes optimal error的时候出现。越接近bayes optimal error，模型越难继续优化，因为这时候的human-level performance可能是比较模糊难以准确定义的。
* 实际上，机器学习模型超过human-level performance是比较困难的。但是只要提供足够多的样本数据，训练复杂的神经网络，模型预测准确性会大大提高，很有可能接近甚至超过human-level performance。但是当算法模型的表现超过human-level performance时，很难再通过人的直觉来继续提高算法模型性能。
### 1.12 提升模型表现
* 提高机器学习模型性能主要要解决两个问题：avoidable bias和variance。我们已经知道，training error与humanlevel-error之间的差值反映的是avoidable bias，dev error与training error之间的差值反映的是variance。
解决avoidable bias的常用方法包括：
Train bigger model
Train longer/better optimization algorithms: momentum, RMSprop, Adam
NN architecture/hyperparameters search
解决variance的常用方法包括：
More data
Regularization: L2, dropout, data augmentation
NN architecture/hyperparameters search

## 2 机器学习（ML）策略2 单值评估指标
### 2.1~2.4 进行误差分析/清楚标注错误的数据
* 对已经建立的机器学习模型进行错误分析（error analysis）十分必要，而且有针对性地、正确地进行error analysis更加重要。这种error analysis虽然简单，但是能够避免花费大量的时间精力去做一些对提高模型性能收效甚微的工作，让我们专注解决影响模型正确率的主要问题。这种error analysis可以同时评估多个影响模型性能的因素，通过各自在错误样本中所占的比例来判断其重要性。通常来说，比例越大，影响越大，越应该花费时间和精力着重解决这一问题。error analysis让我们改进模型更加有针对性，从而提高效率。
* 监督式学习中，训练样本有时候会出现输出y标注错误的情况，如果这些label标错的情况是随机性的（random errors），DL算法对其包容性是比较强的(robust)，一般可以直接忽略，无需修复。然而，如果是系统错误（systematic errors），这将对DL算法造成影响，降低模型性能。如果是dev/test sets中出现incorrectly labeled data，，利用error analysis，统计dev sets中所有分类错误的样本中incorrectly labeled data所占的比例。根据该比例的大小，决定是否需要修正所有incorrectly labeled data，还是可以忽略。
* ### 2.5~2.6 不匹配数据分布的偏差与方差/解决数据不匹配问题
* 在train set与dev/test set分布不一致的情况下，判断是否出现variance的方法是设置train-dev set。Andrew NG给train-dev set的定义是：“Same distribution as trainingset, but not used for training.”也就是说，从原来的train set中分割出一部分作为train-dev set，train-devset不作为训练模型使用，而是与dev set一样用于验证。我们就有training error、training-deverror和dev error三种error。其中，training error与training-dev error的差值反映了variance；training-dev error与dev error的差值反映了data mismatch problem，即样本分布不一致。
* 关于如何解决train set与dev/test set样本分布不一致的问题，有两条建议：
1.Carry out manual error analysis to try to understand difference between
training dev/test sets.
2.Make training data more similar; or collect more data similar to dev/test
sets.可以通过人工合成数据的方法（artificial data synthesis）来使得训练集与验证/测试集相似。
### 2.7~2.8 迁移学习/多任务学习
* 迁移学习的应用场合主要包括三点：
1.Task A and B have the same input x.
2.You have a lot more data for Task A than Task B.
3.Low level features from A could be helpful for learning B.(边缘、角点、曲线、语音等。)
* 多任务学习（multitask learning）就是构建神经网络同时执行多个任务。这与二元分类或者多元分类都不同，多任务学习类似将多个神经网络融合在一起，用
一个网络模型来实现多种分类效果。
* 值得一提的是，Multitask learning与Softmax regression的区别在于Softmax regression是single label的，即输出向量y只有一个元素为1；而Multitask
learning是multiple labels的，即输出向量y可以有多个元素为1。
多任务学习是使用单个神经网络模型来实现多个任务。实际上，也可以分别构建多个神经网络来实现。但是，如果各个任务之间是相似问题（例如都是图片类别检测），则可以使用多任务学习模型。
### 2.9 端到端深度学习
* 端到端（end-to-end）深度学习就是将所有不同阶段的数据处理系统或学习系统模块组合在一起，用一个单一的神经网络模型来实现所有的功能。它将所有模块混合在一起，只关心输入和输出。如果训练样本足够大，神经网络模型足够复杂，那么end-to-end模型性能比传统机器学习分块模型更好。实际上，endtoend让神经网络模型内部去自我训练模型特征，自我调节，增加了模型整体契合度。
* 端到端（end-to-end）深度学习的优点：
Let the data speak
Less hand-designing of components needed
缺点：
May need large amount of data
Excludes potentially useful hand-designed
